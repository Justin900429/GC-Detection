{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \ud83d\ude06 Links to the documentation Introduction \ud83d\ude06 This project is for users to quickly deployed their object detection application. The backend used Google Cloud Vision API for object detection. The release now can only used the built in object detection trained by Google. In the future release, we will add Google AutoML to fulfill costumed needs. Classes \ud83d\ude06 The library contain two classes for use: Detection Get the images with bounding boxes on it. Interface This class supports the GUI interface for the detection images and allows user to upload images to Google Cloud Storage . Installation \ud83d\ude06 Before install the package, we highly recommend to build the virtual env. There are lots of tools user can choose. Below, we demonstrate how to use in conda environment. conda create -n <name-of-env> python=3.8 conda activate <name-of-env> PyPI pip install GCDetection Build from source git clone https://github.com/Justin900429/GC-Detection.git cd GC-Detection pip install -e . Usage \ud83d\ude06 This page show the detail of using the GC_Detection package. GO from here . Example Code \ud83d\ude06 The example code was upload to the github directory, please visit here .","title":"Overview"},{"location":"#overview","text":"Links to the documentation","title":"Overview"},{"location":"#introduction","text":"This project is for users to quickly deployed their object detection application. The backend used Google Cloud Vision API for object detection. The release now can only used the built in object detection trained by Google. In the future release, we will add Google AutoML to fulfill costumed needs.","title":"Introduction"},{"location":"#classes","text":"The library contain two classes for use: Detection Get the images with bounding boxes on it. Interface This class supports the GUI interface for the detection images and allows user to upload images to Google Cloud Storage .","title":"Classes"},{"location":"#installation","text":"Before install the package, we highly recommend to build the virtual env. There are lots of tools user can choose. Below, we demonstrate how to use in conda environment. conda create -n <name-of-env> python=3.8 conda activate <name-of-env> PyPI pip install GCDetection Build from source git clone https://github.com/Justin900429/GC-Detection.git cd GC-Detection pip install -e .","title":"Installation"},{"location":"#usage","text":"This page show the detail of using the GC_Detection package. GO from here .","title":"Usage"},{"location":"#example-code","text":"The example code was upload to the github directory, please visit here .","title":"Example Code"},{"location":"Detection/","text":"Detection \ud83d\ude06 This class provide the function for obtaining the detected images. Link to the class Attributes \ud83d\ude06 Attributes Type Description categories dict Count all the detected objects. img numpy.array Origin image get from the camera. size tuple Size of image. frame numpy.array Image with bounding boxes and categories. Constructor \ud83d\ude06 __init__ ( self , google_kit_json_path : str , categories : list , size : tuple = ( 640 , 480 ), max_results : int = 10 , camera = 0 ) \ud83d\ude06 Create an instance from Detection class. Args google_kit_json_path : Path for the Google API JSON file. To get the API file, please refer to this page . categories : Categories to be detected. All supported types can be found in here . size : Size of the images and frames. max_results : Maximum results for the response. It won't absolutely contain the wanted objects listed in categories . The categories being selected is controlled by the Google Server. camera : Camera to be used. The backend function was using cv2.VideoCapture in OpenCV . Please refer to this link for all the valid input. Method \ud83d\ude06 start ( self ) \ud83d\ude06 Start the object detection and open the camera. end ( self ) \ud83d\ude06 End the detection and release the camera. Logic \ud83d\ude06 Below is a flow chart that shows the logic behind the class. Example \ud83d\ude06 import gcdetection import cv2 # Create detected class and start the detection detection_class = gcdetection . Detection ( google_kit_json_path = \"/path/to/json/file\" , categories = [ \"Person\" , \"Book\" ], size = ( 640 , 480 ), max_results = 10 , camera = 0 ) detection_class . start () # Show the original images and detected images while True : # Obtain images ori_img = detection_class . img detected_img = detection_class . frame # Wait for key key = cv2 . waitKey ( 30 ) & 0xff if key == 27 : # ESC break # Show the images if ori_img is not None : cv2 . imshow ( \"Original image\" , ori_img ) if detected_img is not None : cv2 . imshow ( \"Detected image\" , detected_img ) # Release the resources detection_class . end () cv2 . destroyAllWindows () For more example, please visit the example repository .","title":"Detection"},{"location":"Detection/#detection","text":"This class provide the function for obtaining the detected images. Link to the class","title":"Detection"},{"location":"Detection/#attributes","text":"Attributes Type Description categories dict Count all the detected objects. img numpy.array Origin image get from the camera. size tuple Size of image. frame numpy.array Image with bounding boxes and categories.","title":"Attributes"},{"location":"Detection/#constructor","text":"","title":"Constructor"},{"location":"Detection/#__init__self-google_kit_json_path-str-categories-list-size-tuple-640-480-max_results-int-10-camera0","text":"Create an instance from Detection class. Args google_kit_json_path : Path for the Google API JSON file. To get the API file, please refer to this page . categories : Categories to be detected. All supported types can be found in here . size : Size of the images and frames. max_results : Maximum results for the response. It won't absolutely contain the wanted objects listed in categories . The categories being selected is controlled by the Google Server. camera : Camera to be used. The backend function was using cv2.VideoCapture in OpenCV . Please refer to this link for all the valid input.","title":"__init__(self, google_kit_json_path: str, categories: list, size: tuple = (640, 480), max_results: int = 10, camera=0)"},{"location":"Detection/#method","text":"","title":"Method"},{"location":"Detection/#startself","text":"Start the object detection and open the camera.","title":"start(self)"},{"location":"Detection/#endself","text":"End the detection and release the camera.","title":"end(self)"},{"location":"Detection/#logic","text":"Below is a flow chart that shows the logic behind the class.","title":"Logic"},{"location":"Detection/#example","text":"import gcdetection import cv2 # Create detected class and start the detection detection_class = gcdetection . Detection ( google_kit_json_path = \"/path/to/json/file\" , categories = [ \"Person\" , \"Book\" ], size = ( 640 , 480 ), max_results = 10 , camera = 0 ) detection_class . start () # Show the original images and detected images while True : # Obtain images ori_img = detection_class . img detected_img = detection_class . frame # Wait for key key = cv2 . waitKey ( 30 ) & 0xff if key == 27 : # ESC break # Show the images if ori_img is not None : cv2 . imshow ( \"Original image\" , ori_img ) if detected_img is not None : cv2 . imshow ( \"Detected image\" , detected_img ) # Release the resources detection_class . end () cv2 . destroyAllWindows () For more example, please visit the example repository .","title":"Example"},{"location":"Interface/","text":"Interface \ud83d\ude06 The class show the images detected in Detection class. Also, provide the function to upload the image to Google Cloud Storage . Link to the class Attributes \ud83d\ude06 Attributes Type Description root tkinter.Tk Root object from tkinter. frame numpy.array Image with bounding box and categories. Constructor \ud83d\ude06 __init__ ( self , cfg : str = \"cfg.yml\" ) \ud83d\ude06 Args cfg : Path to the yaml file. The parameters of the cfg file are listed here . Method \ud83d\ude06 start ( self ) \ud83d\ude06 Start the tkinter to work. The code inside is simply self . root . mainloop () extra_info ( self , info : dict ) \ud83d\ude06 Show the user-defined information. The layout and the composition will be rearranged. Example \ud83d\ude06 import gcdetection # Create detection interface and start detecting detect_window = gcdetection . Interface () detect_window . start () For more example, please visit the example repository . Extensive usage. \ud83d\ude06 User can access to the root attribute . Any method that can be used in tkinter can also be implemented here. Below are some examples that users can do. Key binding Documentation from tkinter import gcdetection ... detect_window = gcdetection . Interface () # Should specify the event arguments for tkinter to pass in def task ( event ): pass # Bind key \"k\" to function \"task\" detect_window . root . bind ( \"k\" , task ) ... Continuing task Reference to the usage import gcdetection ... detect_window = gcdetection . Interface () ... # Should specify the event arguments for tkinter to pass in def task ( event ): # TODO: Task to define detect_window . root . after ( 20 , task ) # Run the task every 20 milliseconds detect_window . root . after ( 20 , task ) # Bind key \"k\" to function \"task\" detect_window . root . bind ( \"k\" , task ) ...","title":"Interface"},{"location":"Interface/#interface","text":"The class show the images detected in Detection class. Also, provide the function to upload the image to Google Cloud Storage . Link to the class","title":"Interface"},{"location":"Interface/#attributes","text":"Attributes Type Description root tkinter.Tk Root object from tkinter. frame numpy.array Image with bounding box and categories.","title":"Attributes"},{"location":"Interface/#constructor","text":"","title":"Constructor"},{"location":"Interface/#__init__self-cfg-str-cfgyml","text":"Args cfg : Path to the yaml file. The parameters of the cfg file are listed here .","title":"__init__(self, cfg: str = &quot;cfg.yml&quot;)"},{"location":"Interface/#method","text":"","title":"Method"},{"location":"Interface/#startself","text":"Start the tkinter to work. The code inside is simply self . root . mainloop ()","title":"start(self)"},{"location":"Interface/#extra_infoself-info-dict","text":"Show the user-defined information. The layout and the composition will be rearranged.","title":"extra_info(self, info: dict)"},{"location":"Interface/#example","text":"import gcdetection # Create detection interface and start detecting detect_window = gcdetection . Interface () detect_window . start () For more example, please visit the example repository .","title":"Example"},{"location":"Interface/#extensive-usage","text":"User can access to the root attribute . Any method that can be used in tkinter can also be implemented here. Below are some examples that users can do. Key binding Documentation from tkinter import gcdetection ... detect_window = gcdetection . Interface () # Should specify the event arguments for tkinter to pass in def task ( event ): pass # Bind key \"k\" to function \"task\" detect_window . root . bind ( \"k\" , task ) ... Continuing task Reference to the usage import gcdetection ... detect_window = gcdetection . Interface () ... # Should specify the event arguments for tkinter to pass in def task ( event ): # TODO: Task to define detect_window . root . after ( 20 , task ) # Run the task every 20 milliseconds detect_window . root . after ( 20 , task ) # Bind key \"k\" to function \"task\" detect_window . root . bind ( \"k\" , task ) ...","title":"Extensive usage."},{"location":"Usage/","text":"Usage \ud83d\ude06 Prerequisite \ud83d\ude06 Activate the Cloud Vision API User should follow this link to finish setting up the Cloud API. Create Cloud Storage bucket (Can be ignored for not uploading images) If the users want to upload the detected images to Google Cloud Storage, please refer to this link for creating a bucket. Success Users don't have to set up the environment written in the above first reference. The program will automatically set up the environment for you. Config file \ud83d\ude06 Info To use the class Interface , you must set up the config file using the below template or from here . Below show the template of config file. The format of config file is YAML . --- # GOOGLE_APPLICATION_CREDENTIALS API google-kit-json : \"/path/to/google/kit/json\" # Google Cloud Storage bucket name. # Set null for not uploading images bucket : null # Maximum return object # Note: The result could not be controlled. # To promise for the wanted result, I recommend to set the bigger value. max_request : 10 # Output folder to save images # if not exists, the program will help you create one. # Set null for not saving on local output_path : null # Camera setting. It was controlled by cv2.VideoCapture # See the documentation from OpenCV # https://bit.ly/2ZdQnD5 camera : 0 # Size of images. width : 640 height : 480 # Detection categories. categories : - Person - Book ... google-kit-json This json file can be obtained from the prerequisite part bucket The name of the bucket. For example, if the user create a bucket called images , then leave images in this field. categories See the categories part After creating config file, users can use it as below. import gcdetection interface = gcdetection . Interface ( cfg = \"/path/to/config/file\" ) interface . start () Categories \ud83d\ude06 All the supported categories can be found in here . You can search the wanted category like below image. Cost \ud83d\ude06 Warning The service of Cloud Vision API and Cloud Storage is not free. Cloud storage Pricing for cloud storage Cloud Vision API (Price per 1000 units) First 1000 units/month Units 1001 - 5,000,000 / month Units 5,000,001 and higher / month Free $2.25US $1.50US For more pricing information, please visit the doc of Vision API.","title":"Usage"},{"location":"Usage/#usage","text":"","title":"Usage"},{"location":"Usage/#prerequisite","text":"Activate the Cloud Vision API User should follow this link to finish setting up the Cloud API. Create Cloud Storage bucket (Can be ignored for not uploading images) If the users want to upload the detected images to Google Cloud Storage, please refer to this link for creating a bucket. Success Users don't have to set up the environment written in the above first reference. The program will automatically set up the environment for you.","title":"Prerequisite"},{"location":"Usage/#config-file","text":"Info To use the class Interface , you must set up the config file using the below template or from here . Below show the template of config file. The format of config file is YAML . --- # GOOGLE_APPLICATION_CREDENTIALS API google-kit-json : \"/path/to/google/kit/json\" # Google Cloud Storage bucket name. # Set null for not uploading images bucket : null # Maximum return object # Note: The result could not be controlled. # To promise for the wanted result, I recommend to set the bigger value. max_request : 10 # Output folder to save images # if not exists, the program will help you create one. # Set null for not saving on local output_path : null # Camera setting. It was controlled by cv2.VideoCapture # See the documentation from OpenCV # https://bit.ly/2ZdQnD5 camera : 0 # Size of images. width : 640 height : 480 # Detection categories. categories : - Person - Book ... google-kit-json This json file can be obtained from the prerequisite part bucket The name of the bucket. For example, if the user create a bucket called images , then leave images in this field. categories See the categories part After creating config file, users can use it as below. import gcdetection interface = gcdetection . Interface ( cfg = \"/path/to/config/file\" ) interface . start ()","title":"Config file"},{"location":"Usage/#categories","text":"All the supported categories can be found in here . You can search the wanted category like below image.","title":"Categories"},{"location":"Usage/#cost","text":"Warning The service of Cloud Vision API and Cloud Storage is not free. Cloud storage Pricing for cloud storage Cloud Vision API (Price per 1000 units) First 1000 units/month Units 1001 - 5,000,000 / month Units 5,000,001 and higher / month Free $2.25US $1.50US For more pricing information, please visit the doc of Vision API.","title":"Cost"}]}